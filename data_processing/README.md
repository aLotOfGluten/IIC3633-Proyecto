# Preprocesamiento Twitter15 + Twitter16

Pipeline de preprocesamiento para datasets Twitter15 y Twitter16, generando estructuras optimizadas para sistemas de recomendaciÃ³n y GNNs.

## Contenido

```
.
â”œâ”€â”€ README.md                      # Este archivo
â”œâ”€â”€ preprocess_unified.py          # Script de preprocesamiento 
â”œâ”€â”€ analyze_h1.py                  # Script de anÃ¡lisis exploratorio (EDA)
â”œâ”€â”€ twitter15/                     # Dataset original Twitter15
â”‚   â”œâ”€â”€ label.txt
â”‚   â””â”€â”€ tree/
â”œâ”€â”€ twitter16/                     # Dataset original Twitter16
â”‚   â”œâ”€â”€ label.txt
â”‚   â””â”€â”€ tree/
â”œâ”€â”€ content/                       # Contenido de tweets
â”‚   â”œâ”€â”€ twitter15/
â”‚   â”‚   â”œâ”€â”€ label.txt
â”‚   â”‚   â””â”€â”€ source_tweets.txt
â”‚   â””â”€â”€ twitter16/
â”‚       â”œâ”€â”€ label.txt
â”‚       â””â”€â”€ source_tweets.txt
â”œâ”€â”€ processed_h1/                  # Datos procesados (generado)
â”‚   â”œâ”€â”€ train_interactions.csv
â”‚   â”œâ”€â”€ test_interactions.csv
â”‚   â”œâ”€â”€ train_interactions_idx.csv
â”‚   â”œâ”€â”€ test_interactions_idx.csv
â”‚   â”œâ”€â”€ user_map.csv
â”‚   â”œâ”€â”€ item_map.csv
â”‚   â”œâ”€â”€ item_labels.csv
â”‚   â”œâ”€â”€ item_text_clean.csv
â”‚   â””â”€â”€ stats_summary.txt
â””â”€â”€ plots_and_reports/             # AnÃ¡lisis y visualizaciones (generado)
    â”œâ”€â”€ usuarios_hist.png
    â”œâ”€â”€ items_hist.png
    â”œâ”€â”€ balance_labels.png
    â”œâ”€â”€ cascadas_tamano_hist.png
    â”œâ”€â”€ cascadas_profundidad_hist.png
    â”œâ”€â”€ viralidad_fake_vs_real.png
    â”œâ”€â”€ resumen_stats.csv
    â”œâ”€â”€ top_usuarios.csv
    â””â”€â”€ top_items.csv
```

## Uso RÃ¡pido

### 1. Preprocesamiento

```bash
python3 preprocess_unified.py
```

Esto generarÃ¡ automÃ¡ticamente todos los archivos en `processed_h1/`.

### 2. AnÃ¡lisis Exploratorio (EDA)

```bash
python3 analyze_h1.py
```

Genera visualizaciones y estadÃ­sticas descriptivas en `plots_and_reports/`.

## ConfiguraciÃ³n

Editar la clase `Config` en `preprocess_unified.py` (lÃ­neas 15-23):

```python
class Config:
    DATASETS = ["twitter15", "twitter16"]
    OUTPUT_DIR = "processed_h1"
    CONTENT_DIR = "content"
    MIN_INTERACTIONS = 8          # MÃ­nimo de interacciones por usuario
    RANDOM_STATE = 42
    LABEL_STRATEGY = '4class'     # Estrategia de etiquetado
```

### Estrategias de Etiquetado

| Estrategia | DescripciÃ³n | Clases |
|-----------|-------------|--------|
| `4class` | 4 categorÃ­as originales (default) | 0=true, 1=false, 2=unverified, 3=non-rumor |
| `3class` | Agrupa ambiguos | 0=true, 1=false, 2=ambiguous |
| `binary_strict` | Solo true vs false | 0=false, 1=true |
| `binary_all` | True vs resto | 0=fake/otros, 1=true |

## Archivos Generados

### Interacciones
- `train_interactions.csv` - Entrenamiento con IDs originales
- `test_interactions.csv` - Test con IDs originales
- `train_interactions_idx.csv` - Entrenamiento con Ã­ndices numÃ©ricos
- `test_interactions_idx.csv` - Test con Ã­ndices numÃ©ricos

**Formato:** `user_id, item_id, interaction` (o `user_idx, item_idx, interaction`)

### Mapeos
- `user_map.csv` - Mapeo `user_id â†’ user_idx` (0 a N)
- `item_map.csv` - Mapeo `item_id â†’ item_idx` (0 a M)

### Etiquetas y Texto
- `item_labels.csv` - `item_id, item_idx, label, binary_label, multiclass_label, dataset`
- `item_text_clean.csv` - `item_id, item_idx, text_clean` (texto procesado de tweets)

### EstadÃ­sticas
- `stats_summary.txt` - MÃ©tricas completas del procesamiento

## AnÃ¡lisis Exploratorio de Datos (EDA)

El script `analyze_h1.py` genera un anÃ¡lisis completo del dataset procesado, enfocado en **viralidad** y **desinformaciÃ³n**.

### EjecuciÃ³n

```bash
python3 analyze_h1.py
```

**Requisitos:** `pandas`, `numpy`, `matplotlib`, `scipy` (opcional para test estadÃ­stico)

### AnÃ¡lisis Generados

#### ðŸ“Š GrÃ¡ficos (`plots_and_reports/`)

1. **`usuarios_hist.png`** - DistribuciÃ³n de interacciones por usuario
   - Muestra mediana y filtro mÃ­nimo (8 interacciones)
   - Justifica decisiones de preprocesamiento

2. **`items_hist.png`** - DistribuciÃ³n de interacciones por item (long-tail)
   - Evidencia la distribuciÃ³n long-tail tÃ­pica de redes sociales
   - Muestra items altamente virales vs. poco difundidos

3. **`balance_labels.png`** - Balance de clases multiclase
   - 4 categorÃ­as: `false`, `true`, `unverified`, `non-rumor`
   - Porcentajes y conteos absolutos
   - Confirma dataset balanceado (~25% cada clase)

4. **`cascadas_tamano_hist.png`** - DistribuciÃ³n de tamaÃ±o de cascadas
   - Histograma mostrando nÃºmero de usuarios por cascada
   - LÃ­neas de promedio y mediana para referencia
   - Visualiza la distribuciÃ³n de alcance de difusiÃ³n

5. **`cascadas_profundidad_hist.png`** - DistribuciÃ³n de profundidad de cascadas
   - Histograma mostrando niveles de propagaciÃ³n
   - LÃ­neas de promedio y mediana para referencia
   - Muestra cuÃ¡n profundas son las cascadas de difusiÃ³n

6. **`viralidad_fake_vs_real.png`** - Viralidad comparativa
   - GrÃ¡fico de barras con barras de error (desviaciÃ³n estÃ¡ndar)
   - Compara promedio de interacciones: Noticias Falsas vs Verdaderas
   - **Incluye test estadÃ­stico:** Mann-Whitney U test
   - Muestra si las noticias falsas son significativamente mÃ¡s virales

#### ðŸ“‹ Tablas CSV (`plots_and_reports/`)

1. **`resumen_stats.csv`** - EstadÃ­sticas globales del dataset
   - Usuarios, items, interacciones, densidad
   - DistribuciÃ³n multiclase (n y %)

2. **`top_items.csv`** - Top 10 items mÃ¡s virales
   - Identificadores, nÃºmero de interacciones
   - Tipo (Fake/Real), categorÃ­a a anlizar

3. **`top_usuarios.csv`** - Top 10 usuarios mÃ¡s activos
   - Identificadores, nÃºmero de interacciones

### Hallazgos Principales

Con el dataset procesado (configuraciÃ³n por defecto):

| MÃ©trica | Valor |
|---------|-------|
| **Viralidad Fake** | 32.99 interacciones promedio |
| **Viralidad Real** | 18.07 interacciones promedio |
| **Ratio Fake/Real** | 1.8x mÃ¡s viral |
| **Significancia estadÃ­stica** | p < 0.001 (altamente significativo) |
| **Top 10 items virales** | 100% Fake |
| **TamaÃ±o cascada promedio** | 411.3 usuarios |
| **Profundidad cascada promedio** | 4.7 niveles |

**ConclusiÃ³n:** Las noticias falsas son significativamente mÃ¡s virales que las verdaderas en este dataset.

## Pipeline de Procesamiento

El script estÃ¡ estructurado en funciones modulares con type hints completos:

1. **`load_data()`** - Carga labels y contenido de tweets desde ambos datasets
   - Lee `label.txt` para etiquetas de veracidad
   - Lee `source_tweets.txt` y aplica limpieza de texto (URLs â†’ `URL`, mentions â†’ `@USER`, etc.)

2. **`extract_interactions()`** - Extrae interacciones user-item desde Ã¡rboles de propagaciÃ³n
   - Usuario participa en Ã¡rbol â†’ `interaction=1`
   - Construye matriz sparse eficientemente usando listas de columnas

3. **`filter_users()`** - Elimina usuarios con < `MIN_INTERACTIONS` (default: 8)

4. **`split_train_test()`** - DivisiÃ³n train/test usando leave-one-out
   - Ãšltima interacciÃ³n de cada usuario â†’ test (~92% train, ~8% test)
   - Usa `groupby().idxmax()` para mÃ¡xima eficiencia

5. **`create_mappings()`** - Genera Ã­ndices numÃ©ricos para usuarios e items

6. **`save_interactions()`** - Guarda interacciones con IDs e Ã­ndices

7. **`save_labels_and_text()`** - Guarda labels (binarias y multiclase) + texto limpio

8. **`print_final_stats()`** - Imprime estadÃ­sticas finales del dataset

## EstadÃ­sticas del Dataset

Con configuraciÃ³n por defecto:

| MÃ©trica | Valor |
|---------|-------|
| Usuarios | 4,856 |
| Items | 2,178 |
| Interacciones | 63,850 |
| Densidad | 0.60% |
| Interacciones/usuario | 13.15 |
| Interacciones/item | 29.32 |
| Tweets con texto | 2,178 (100%) |

### DistribuciÃ³n de Clases (4-class)

| Clase | Label | Items | % |
|-------|-------|-------|---|
| 0 | true | 536 | 24.6% |
| 1 | false | 511 | 23.5% |
| 2 | unverified | 555 | 25.5% |
| 3 | non-rumor | 576 | 26.4% |

Balance: ~25% por clase âœ“

### ContribuciÃ³n
- Twitter15: 64.2% (1,398 items)
- Twitter16: 35.8% (780 items)

## GuÃ­a de Uso para Sistemas de RecomendaciÃ³n

### Archivos Necesarios

**Para modelos base (UKNN, Most Popular, Random):**
- `train_interactions_idx.csv` - Matriz user-item (4856 Ã— 2178)
- `test_interactions_idx.csv` - EvaluaciÃ³n
- `user_map.csv`, `item_map.csv` - Mapeos de Ã­ndices
- `item_labels.csv` - AnÃ¡lisis de bias por clase

### 1. ImplementaciÃ³n de Modelos

#### UKNN (User-based KNN)
**Proceso:**
1. Construir matriz sparse user-item con las interacciones de entrenamiento
2. Entrenar KNN con similaridad coseno entre usuarios
3. Para recomendar: encontrar k vecinos mÃ¡s similares y agregar sus items
4. Excluir items ya interactuados por el usuario
5. Sugerencia: k=20 vecinos como punto de partida

#### Most Popular
**Proceso:**
1. Contar interacciones por item en el conjunto de entrenamiento
2. Ordenar items por popularidad (mÃ¡s interacciones primero)
3. Para recomendar: devolver los top-K items mÃ¡s populares
4. Excluir items ya interactuados por el usuario

#### Random
**Proceso:**
1. Obtener lista de todos los items disponibles
2. Para recomendar: seleccionar K items aleatoriamente
3. Excluir items ya interactuados por el usuario
4. Sirve como baseline para comparar con otros mÃ©todos

---

### **EXTRA (Solo si hay tiempo - Ideal para sacarnos una buena nota)**

#### IKNN (Item-based KNN)
**Proceso:**
1. Construir matriz sparse user-item con las interacciones de entrenamiento
2. Calcular similaridad coseno entre **items** (transponer matriz user-item)
3. Para recomendar a un usuario:
   - Identificar items con los que el usuario ya interactuÃ³
   - Para cada item del catÃ¡logo: calcular score como suma ponderada de similaridades con items del usuario
   - Ordenar por score y devolver top-K
4. Sugerencia: k=20 vecinos como punto de partida

**Diferencia clave con UKNN:**
- UKNN: "recomendar items que usuarios similares a ti consumieron"
- IKNN: "recomendar items similares a los que ya consumiste"

#### TF-IDF + Similaridad de Contenido
**Archivos necesarios:**
- `item_text_clean.csv` - Texto limpio de tweets
- `train_interactions_idx.csv` - Para filtrar items ya vistos

**Proceso:**
1. Cargar texto de tweets desde `item_text_clean.csv`
2. Construir matriz TF-IDF usando `sklearn.TfidfVectorizer`
   - ParÃ¡metros sugeridos: `max_features=5000`, `ngram_range=(1,2)`, `min_df=2`
3. Calcular similaridad coseno entre todos los pares de items
4. Para recomendar a un usuario:
   - Identificar items con los que interactuÃ³ en train
   - Para cada item del usuario: obtener los K items mÃ¡s similares por contenido
   - Agregar scores y ordenar
   - Excluir items ya interactuados
5. Devolver top-K recomendaciones

**AnÃ¡lisis recomendado:**
- Â¿Items de la misma clase (true/false) tienen mayor similaridad textual?
- Â¿TF-IDF amplifica o reduce bias comparado con mÃ©todos colaborativos?

---

### 2. AnÃ¡lisis de Recomendaciones segÃºn Labels

**MÃ©tricas de anÃ¡lisis recomendadas:**

| MÃ©trica | Objetivo |
|---------|----------|
| **Bias de labels** | Â¿El sistema recomienda mÃ¡s un tipo de rumor que otro? |
| **Precision@K por clase** | PrecisiÃ³n separada para cada label (true, false, etc.) |
| **Exposure por label** | Â¿QuÃ© clases de rumores tienen mÃ¡s visibilidad? |
| **Fairness** | Comparar distribuciÃ³n en recomendaciones vs dataset base (~25% por clase) |
| **Coverage por clase** | Â¿QuÃ© porcentaje de items de cada label son recomendados? |

**Consideraciones importantes:**
- El dataset estÃ¡ balanceado (~25% por clase), usar como baseline de comparaciÃ³n
- Evaluar si el sistema amplifica ciertos tipos de rumores (ej. mÃ¡s `false` que `true`)
- Comparar los 3 modelos: Â¿UKNN amplifica mÃ¡s bias que Random o Most Popular?
- Analizar si usuarios que interactÃºan con `true` reciben recomendaciones sesgadas
- Considerar el impacto social de recomendar mÃ¡s rumores falsos vs verificados

## Referencias

**Twitter15:**
```bibtex
@inproceedings{liu2015real,
  title={Real-time Rumor Debunking on Twitter},
  author={Liu, Xiaomo and Nourbakhsh, Armineh and Li, Quanzhi and Fang, Rui and Shah, Sameena},
  booktitle={CIKM},
  pages={1867--1870},
  year={2015}
}
```

**Twitter16:**
```bibtex
@inproceedings{ma2016detecting,
  title={Detecting Rumors from Microblogs with Recurrent Neural Networks},
  author={Ma, Jing and Gao, Wei and Mitra, Prasenjit and Kwon, Sejeong and Jansen, Bernard J. and Wong, Kam-Fai and Meeyoung, Cha},
  booktitle={IJCAI},
  year={2016}
}
```

**Dataset:**
```bibtex
@inproceedings{ma2017detect,
  title={Detect Rumors in Microblog Posts Using Propagation Structure via Kernel Learning},
  author={Ma, Jing and Gao, Wei and Wong, Kam-Fai},
  booktitle={ACL},
  volume={1},
  pages={708--717},
  year={2017}
}
```

---

## Fuentes del Dataset

**Interacciones y estructura de propagaciÃ³n:**
- [gszswork/Twitter15_16_dataset](https://github.com/gszswork/Twitter15_16_dataset)

**Contenido de tweets (source_tweets.txt):**
- [Rumor Detection ACL 2017 - Kaggle](https://www.kaggle.com/datasets/syntheticprogrammer/rumor-detection-acl-2017/data)
